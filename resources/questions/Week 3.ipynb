{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c208f19-2785-46f9-85d9-f5b27cfe91ce",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" style=\"text-align: center;\">\n",
    "\n",
    "# لیگ علم داده\n",
    "### انجمن هوش مصنوعی دانشگاه خوارزمی - کارگروه کاوش عملی\n",
    "#### هفته سوم: مدلسازی و ارزیابی \n",
    "**نام و نام خانوادگی:**  \n",
    "**سرگروه:**  \n",
    "**تاریخ ارسال:** \n",
    "\n",
    "---\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01218e43-d217-4e2c-b47d-5b3ad57f9266",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "### چالش 1: \n",
    "\n",
    "فرض کنید شما مدیر تیم دیتا هستید. دو کارآموز جدید برای پروژه استخدام کرده‌اید و هر کدام یک مدل برای پیش‌بینی نمرات ارائه داده‌اند\n",
    "\n",
    "* **کارآموز الف (Parsa):** مدلی با خطای RMSE = 1.07 آورده است.\n",
    "* **کارآموز ب (Sara):** مدلی با خطای خیره‌کننده RMSE = 0.22 آورده و ادعا می‌کند مدلش تقریباً بدون نقص است!\n",
    "\n",
    "مدیر پروژه هیجان‌زده است و می‌خواهد همین امروز مدل سارا (کد دوم) را روی سرور دانشگاه مستقر کند چون خطای آن نزدیک به صفر است. اما قبل از استقرار تصمیم گرفته تا با شما مشورت کند.\n",
    "\n",
    "الف) تحلیل خود را از کد های سارا و پارسا بنویسید، هر کدام از چه روش ها و مدل هایی استفاده کردند، مزایا و معایت هر کدام چیست؟\n",
    "\n",
    "ب) یک گزارش فنی کوتاه برای \"رد\" یا \"تایید\" این مدل‌ها بنویسید.\n",
    " و توصیه نهایی خود را به مدیر پروژه اعلام کنید\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e880fd63-7ba7-418d-a243-3f0f112dbc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE after Robust Scaling and PCA with Label Encoding: 1.0732279270607483\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "\n",
    "\n",
    "categorical_cols = ['school', 'sex', 'address', 'famsize', 'Pstatus', 'schoolsup', \n",
    "                    'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', \n",
    "                    'Mjob', 'Fjob', 'reason', 'guardian']\n",
    "ordinal_cols = ['Medu', 'Fedu', 'age', 'traveltime', 'studytime', 'failures', \n",
    "                'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health']\n",
    "numeric_cols = ['G1', 'G2', 'G3', 'absences']\n",
    "\n",
    "\n",
    "train_data['Fedu_Medu'] = train_data['Fedu'] + train_data['Medu']\n",
    "train_data['Walc_Dalc'] = train_data['Walc'] + train_data['Dalc']\n",
    "train_data['G1_G2'] = train_data['G1'] + train_data['G2']\n",
    "\n",
    "ordinal_cols = [col for col in ordinal_cols if col not in ['Fedu', 'Medu', 'Walc', 'Dalc']]\n",
    "numeric_cols = [col for col in numeric_cols if col not in ['G1', 'G2']]\n",
    "numeric_cols += ['Fedu_Medu', 'Walc_Dalc', 'G1_G2']\n",
    "\n",
    "X = train_data.drop('G3', axis=1)\n",
    "y = train_data['G3']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_copy = X_train.copy()\n",
    "X_val_copy = X_val.copy()\n",
    "\n",
    "X_train_copy['G3'] = y_train\n",
    "X_val_copy['G3'] = y_val\n",
    "\n",
    "def elliptic_envelope_outliers(df, cols):\n",
    "    ee = EllipticEnvelope(contamination=0.05, random_state=42)\n",
    "    df['anomaly'] = ee.fit_predict(df[cols])\n",
    "    df = df[df['anomaly'] == 1].drop('anomaly', axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "X_train_ee = elliptic_envelope_outliers(X_train_copy.copy(), numeric_cols)\n",
    "X_val_ee = elliptic_envelope_outliers(X_val_copy.copy(), numeric_cols)\n",
    "\n",
    "y_train_ee = X_train_ee.pop('G3')\n",
    "y_val_ee = X_val_ee.pop('G3')\n",
    "\n",
    "\n",
    "categorical_cols = [col for col in categorical_cols if col in X_train_ee.columns]\n",
    "ordinal_cols = [col for col in ordinal_cols if col in X_train_ee.columns]\n",
    "numeric_cols = [col for col in numeric_cols if col in X_train_ee.columns]\n",
    "\n",
    "\n",
    "def build_and_evaluate_model(preprocessor, X_train, X_val, y_train, y_val):\n",
    "    pca = PCA(n_components=0.95)\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('pca', pca),\n",
    "        ('model', LinearRegression())\n",
    "    ])\n",
    "    \n",
    " \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "    \n",
    " \n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    return rmse\n",
    "\n",
    "\n",
    "preprocessor_robust = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('ordinal', OrdinalEncoder(), categorical_cols + ordinal_cols),  \n",
    "        ('scaler', RobustScaler(), numeric_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "\n",
    "rmse_robust_pca = build_and_evaluate_model(preprocessor_robust, X_train_ee, X_val_ee, y_train_ee, y_val_ee)\n",
    "print(f\"RMSE after Robust Scaling and PCA with Label Encoding: {rmse_robust_pca}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c21bcb4-9e1d-46d4-9ab5-f95a3aeff42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest K-Fold Cross-Validated RMSE: 0.221450047966295\n",
      "ExtraTrees K-Fold Cross-Validated RMSE: 0.2526895846633275\n",
      "CatBoost K-Fold Cross-Validated RMSE: 0.24739834632359012\n",
      "GradientBoosting K-Fold Cross-Validated RMSE: 0.23681217246769765\n",
      "{'RandomForest': 0.221450047966295, 'ExtraTrees': 0.2526895846633275, 'CatBoost': 0.24739834632359012, 'GradientBoosting': 0.23681217246769765}\n",
      "Stacking Model K-Fold Cross-Validated RMSE: 0.2770533467873001\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "\n",
    "\n",
    "categorical_cols = ['school', 'sex', 'address', 'famsize', 'Pstatus', 'schoolsup', \n",
    "                    'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', \n",
    "                    'Mjob', 'Fjob', 'reason', 'guardian']\n",
    "ordinal_cols = ['Medu', 'Fedu', 'age', 'traveltime', 'studytime', 'failures', \n",
    "                'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health']\n",
    "numeric_cols = ['G1', 'G2', 'G3', 'absences']\n",
    "\n",
    "\n",
    "train_data['Fedu_Medu'] = train_data['Fedu'] + train_data['Medu']\n",
    "train_data['Walc_Dalc'] = train_data['Walc'] + train_data['Dalc']\n",
    "train_data['G1_G2'] = train_data['G1'] + train_data['G2']\n",
    "\n",
    "\n",
    "ordinal_cols = [col for col in ordinal_cols if col not in ['Fedu', 'Medu', 'Walc', 'Dalc']]\n",
    "numeric_cols = [col for col in numeric_cols if col not in ['G1', 'G2']]\n",
    "numeric_cols += ['Fedu_Medu', 'Walc_Dalc', 'G1_G2']\n",
    "\n",
    "\n",
    "encoder = OrdinalEncoder()\n",
    "train_data[categorical_cols + ordinal_cols] = encoder.fit_transform(train_data[categorical_cols + ordinal_cols])\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_data[numeric_cols] = scaler.fit_transform(train_data[numeric_cols])\n",
    "\n",
    "X = train_data.drop('G3', axis=1)\n",
    "y = train_data['G3']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_copy = X_train.copy()\n",
    "X_val_copy = X_val.copy()\n",
    "\n",
    "X_train_copy['G3'] = y_train\n",
    "X_val_copy['G3'] = y_val\n",
    "\n",
    "\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "def elliptic_envelope_outliers(df, cols):\n",
    "    ee = EllipticEnvelope(contamination=0.05, random_state=42)\n",
    "    df['anomaly'] = ee.fit_predict(df[cols])\n",
    "    df = df[df['anomaly'] == 1].drop('anomaly', axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "X_train_ee = elliptic_envelope_outliers(X_train_copy.copy(), numeric_cols)\n",
    "X_val_ee = elliptic_envelope_outliers(X_val_copy.copy(), numeric_cols)\n",
    "\n",
    "y_train_ee = X_train_ee.pop('G3')\n",
    "y_val_ee = X_val_ee.pop('G3')\n",
    "\n",
    "\n",
    "models = {\n",
    "    'RandomForest': RandomForestRegressor(),\n",
    "    'ExtraTrees': ExtraTreesRegressor(),\n",
    "    'CatBoost': CatBoostRegressor(silent=True),\n",
    "    'GradientBoosting': GradientBoostingRegressor()\n",
    "}\n",
    "\n",
    "\n",
    "def kfold_cross_validation_evaluation(models, X, y):\n",
    "    results = {}\n",
    "    \n",
    "    # KFold با 5 بخش\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        # پایپ‌لاین برای هر مدل\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('model', model)\n",
    "        ])\n",
    "        \n",
    "        rmse_list = []\n",
    "        for train_index, val_index in kf.split(X):\n",
    "            X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
    "            y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
    "            \n",
    "            pipeline.fit(X_train_fold, y_train_fold)\n",
    "            y_pred = pipeline.predict(X_val_fold)\n",
    "            \n",
    "            rmse = np.sqrt(mean_squared_error(y_val_fold, y_pred))\n",
    "            rmse_list.append(rmse)\n",
    "        \n",
    "        avg_rmse = np.mean(rmse_list)\n",
    "        results[model_name] = avg_rmse\n",
    "        print(f'{model_name} K-Fold Cross-Validated RMSE: {avg_rmse}')\n",
    "    \n",
    "    return results\n",
    "\n",
    "kfold_cv_results = kfold_cross_validation_evaluation(models, X_train_ee, y_train_ee)\n",
    "\n",
    "print(kfold_cv_results)\n",
    "\n",
    "\n",
    "stacking_model = StackingRegressor(\n",
    "    estimators=[\n",
    "        ('RandomForest', RandomForestRegressor()),\n",
    "        ('ExtraTrees', ExtraTreesRegressor()),\n",
    "        ('CatBoost', CatBoostRegressor(silent=True)),\n",
    "        ('GradientBoosting', GradientBoostingRegressor())\n",
    "    ],\n",
    "    final_estimator=GradientBoostingRegressor() \n",
    ")\n",
    "\n",
    "\n",
    "def evaluate_stacking_model(model, X, y):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    rmse_list = []\n",
    "    \n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
    "        \n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        y_pred = model.predict(X_val_fold)\n",
    "        \n",
    "        rmse = np.sqrt(mean_squared_error(y_val_fold, y_pred))\n",
    "        rmse_list.append(rmse)\n",
    "    \n",
    "    avg_rmse = np.mean(rmse_list)\n",
    "    print(f'Stacking Model K-Fold Cross-Validated RMSE: {avg_rmse}')\n",
    "    return avg_rmse\n",
    "\n",
    "\n",
    "stacking_rmse = evaluate_stacking_model(stacking_model, X_train_ee, y_train_ee)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d505f8c5-dcd2-402f-9fa5-7c4d1ffc1261",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" style=\"width: 100%; overflow: hidden; white-space: nowrap; text-align: center; margin: 60px 0; user-select: none;\">\n",
    "    <span style=\"color: #d97706; font-size: 18px; letter-spacing: 15px; opacity: 0.6;\">\n",
    "        ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆\n",
    "    </span>\n",
    "    <div style=\"font-size: 12px; color: #9ca3af; margin-top: -10px; background: #fff; display: inline-block; padding: 0 15px; position: relative; bottom: 12px;\">\n",
    "        Next Challenge\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3629c56-ea1a-4bff-90ee-9cf6339c4cbe",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "### چالش 2: برقراری عدالت در مدل\n",
    "\n",
    "\n",
    "پس از اینکه توابع پاکسازی و مهندسی ویژگی که جلسه پیش ساختید را اجرا کردید و با توجه به نکاتی در چالش قبل یاد گرفتید خودتان یک پایپ‌لاین کامل شامل مدل دلخواهتان بنویسید (رگرسیون یا درختی یا ...)؛ ابتدا `RMSE` را روی کل ولیدیشن حساب کنید. سپس `RMSE` را به تفکیک روی مدارس `GP` و `MS` جداگانه بررسی کنید. آیا مدل شما در هر دو مدرسه به یک اندازه خوب عمل می‌کند؟\n",
    "\n",
    "---\n",
    "\n",
    "#### ماموریت ۱: اصلاح استراتژی تقسیم داده (Stratified Splitting)\n",
    "\n",
    "حالا که مشکل را دیدید، باید آن را حل کنید. یکی از دلایل اصلی این مشکل، نحوه تقسیم داده‌ها (`train_test_split`) است. اگر تصادفی تقسیم کنید، ممکن است در داده‌های `Train` کثرت نمونه‌های `MS` آنقدر کم باشد که مدل اصلاً الگوی آن‌ها را یاد نگیرد.\n",
    "\n",
    "* **اقدام:** کد تقسیم داده خود را اصلاح کنید. به جای تقسیم رندوم ساده، از روش **\"Stratified Splitting\"** استفاده کنید تا مطمئن شوید نسبت مدرسه `MS` در داده‌های `Train` و `Test` حفظ می‌شود.\n",
    "* **راهنمایی:** در تابع `train_test_split` پارامتری به نام `stratify` وجود دارد. آن را بر اساس ستون `school` تنظیم کنید.\n",
    "* ** حالا دوباره مدل را آموزش دهید و `RMSE`های تفکیک شده را چک کنید. آیا فاصله بین خطای دو مدرسه کمتر شد؟\n",
    "\n",
    "---\n",
    "\n",
    "#### ماموریت ۲: تنظیم وزن نمونه‌ها (Sample Weighting)\n",
    "\n",
    "اگر `Stratification` کافی نبود، باید زورِ مدل را زیاد کنید! به مدل بگویید: \"اشتباه کردن روی دانش‌آموزان مدرسه `MS` هزینه بیشتری دارد!\"\n",
    "\n",
    "* **اقدام:** وزن هر نمونه را محاسبه کنید (**Compute Sample Weights**). به دانش‌آموزان `MS` وزن بیشتری بدهید (معکوس فراوانی‌شان). مثلاً اگر نسبت `GP` به `MS` برابر ۹ به ۱ است، وزن `MS` را ۹ برابر `GP` کنید. این وزن‌ها را هنگام آموزش به مدل بدهید (اکثر مدل‌های Scikit-Learn مثل `RandomForest` در متد `.fit()` پارامتری به نام `sample_weight` دارند).\n",
    "* **نتیجه نهایی:** آیا با این کار، عدالت برقرار شد؟ (ممکن است  کل کمی زیاد شود، اما  مدرسه `MS` باید کاهش یابد).\n",
    "\n",
    "---\n",
    "\n",
    "#### بخش امتیازی: بررسی ناتوازنی در هدف (Target Imbalance)\n",
    "\n",
    "شما در این سوال با مفهوم **Feature Imbalance** آشنا شدید، اما یک ناتوازنی دیگر هم می‌تواند وجود داشته باشد که بررسی نکردیم: **Target Imbalance**.\n",
    "\n",
    "* این بار `RMSE` به تفکیک نمره باشد؛ مثلاً سه دسته دانش‌آموز ضعیف، متوسط و قوی.\n",
    "* آیا وزن سه دسته یکسان است؟\n",
    "* اگر یکسان نیست چه راهکاری پیشنهاد می‌دهید؟\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f996e21-f709-4930-9b4e-06348830fc26",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" style=\"width: 100%; overflow: hidden; white-space: nowrap; text-align: center; margin: 60px 0; user-select: none;\">\n",
    "    <span style=\"color: #d97706; font-size: 18px; letter-spacing: 15px; opacity: 0.6;\">\n",
    "        ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆\n",
    "    </span>\n",
    "    <div style=\"font-size: 12px; color: #9ca3af; margin-top: -10px; background: #fff; display: inline-block; padding: 0 15px; position: relative; bottom: 12px;\">\n",
    "        Next Challenge\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad85fe0d-c2a0-4fc7-8d35-d9f6ab58732a",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "### چالش 3: ترکیب و مقایسه مدل ها"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b53bd0-d1ad-48e3-9e83-83964c810011",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "پس از اینکه پایپ‌لاین‌های پاک‌سازی و مهندسی ویژگی هفته قبل را اجرا کردید، وقت انتخاب \"مدل\" است. ما سه کاندیدا محبوب داریم:\n",
    "\n",
    "* **Linear Regression:** سریع، ساده، اما شاید ضعیف در برابر الگوهای پیچیده.\n",
    "* **Lasso Regression:** هوشمند در حذف ویژگی‌های اضافه (Feature Selection خودکار).\n",
    "* **Random Forest:** قدرتمند و غیرخطی، اما با خطر Overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "#### ماموریت ۱: ارزیابی اولیه و اعتبارسنجی متقاطع\n",
    "\n",
    "از `cross_val_score` با `cv=5` استفاده کنید تا میانگین خطای ($RMSE$) هر سه مدل را بدست آورید.\n",
    "\n",
    "* **تحلیل نموداری:** یک نمودار **Boxplot** بکشید که توزیع خطاهای این ۵ فولد را برای هر سه مدل نشان دهد.\n",
    "* **سوال:** چرا در این پروژه، شبکه عصبی را جزو گزینه‌های محبوب نیاوردیم؟\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### ماموریت ۲: تشخیص بیش‌برازش (Overfitting) و پایداری\n",
    "\n",
    "یک تابع بنویسید که برای هر سه مدل کارهای زیر را انجام دهد:\n",
    "\n",
    "1.  مدل را روی کل `X_train` فیت کند و $RMSE$ روی خودِ `X_train` را حساب کند (نام آن را بگذارید: **Train Error**).\n",
    "2.  با استفاده از `cross_val_score` (با `cv=5`)، میانگین $RMSE$ روی داده‌های اعتبارسنجی را حساب کند (نام آن را بگذارید: **CV Error**).\n",
    "\n",
    "* **تحلیل نموداری (Bar Plot):** یک نمودار میله‌ای گروهی (**Grouped Bar Plot**) رسم کنید. برای هر مدل، دو میله کنار هم داشته باشید: یکی برای Train Error و یکی برای CV Error.\n",
    "\n",
    "\n",
    "\n",
    "**سوالات تحلیلی:**\n",
    "* در کدام مدل، ارتفاع دو میله تقریباً برابر است؟ (نشانه پایداری/Underfitting).\n",
    "* در کدام مدل، میله‌ی Train بسیار کوتاه اما میله‌ی CV بلند است؟ (نشانه Overfitting).\n",
    "* بر اساس اصل **\"تیغ اوکام\" (Occam's Razor)**، اگر خطای CV دو مدل نزدیک به هم بود، کدام را انتخاب می‌کنید؟ مدلی که شکاف کمتری دارد یا مدلی که پیچیده‌تر است؟\n",
    "\n",
    "---\n",
    "\n",
    "#### ماموریت ۳: تشکیل شورا (Weighted Averaging)\n",
    "\n",
    "حالا که نقاط قوت و ضعف هر مدل را دیدید، بیایید به جای انتخاب یک نفر، یک \"شورا\" تشکیل دهیم.\n",
    "\n",
    "**اقدام:**\n",
    "سه سناریوی مختلف برای وزن‌دهی (**Weighted Averaging**) تعریف کنید و $RMSE$ نهایی را روی داده‌های Validation محاسبه کنید:\n",
    "1.  **سناریوی دموکراسی (Simple Average):** به همه مدل‌ها وزن برابر بدهید. \n",
    "2.  **سناریوی نخبه‌گرا (Best Model Dominance):** به مدلی که در ماموریت ۱ کمترین خطای CV را داشت، وزن ۰.۷ و به بقیه ۰.۱۵ بدهید.\n",
    "3.  **سناریوی محافظه‌کار (Conservative / Occam’s Style):** به مدل‌های خطی (Lasso/Linear) مجموعاً وزن ۰.۸ و به Random Forest وزن ۰.۲ بدهید.\n",
    "\n",
    "**تحلیل نهایی:**\n",
    "* کدام ترکیب برنده شد؟\n",
    "* اگر ترکیب محافظه‌کار برنده شد، دلیلش چیست؟ (آیا RF نویزها را یاد گرفته بود که با کم کردن وزنش، دقت بالا رفت؟).\n",
    "* اگر ترکیب نخبه‌گرا برنده شد، آیا ریسک Overfitting در داده‌های جدید (Test) وجود دارد؟\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47698627-a789-4fa1-b096-8ff088396dfa",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "#### راهنمایی برای ماموریت ۲\n",
    "\n",
    "برای رسم نمودارهای این بخش، می‌توانید از ساختار قطعه کد زیر الگوبرداری کنید:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f636ecf-48aa-43b9-b706-54b6f693bd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def compare_models_visual(models, X, y):\n",
    "    model_names = []\n",
    "    train_errors = []\n",
    "    cv_errors = []\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        model.fit(X, y)\n",
    "        y_pred_train = model.predict(X)\n",
    "        train_rmse = np.sqrt(mean_squared_error(y, y_pred_train))\n",
    "        \n",
    "        cv_scores = -cross_val_score(model, X, y, cv=5, scoring='neg_root_mean_squared_error')\n",
    "        cv_rmse = cv_scores.mean()\n",
    "        \n",
    "        model_names.append(name)\n",
    "        train_errors.append(train_rmse)\n",
    "        cv_errors.append(cv_rmse)\n",
    "    \n",
    "    x = np.arange(len(model_names))\n",
    "    width = 0.35\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    rects1 = ax.bar(x - width/2, train_errors, width, label='Train Error (Overfitting Check)', color='skyblue')\n",
    "    rects2 = ax.bar(x + width/2, cv_errors, width, label='CV Error (Real Performance)', color='salmon')\n",
    "    \n",
    "    ax.set_ylabel('RMSE')\n",
    "    ax.set_title('Train vs Validation Error: Detecting Overfitting')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(model_names)\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# اجرا\n",
    "# models = {'Linear': LinearRegression(), 'Lasso': Lasso(alpha=0.1), 'RandomForest': RandomForestRegressor()}\n",
    "# compare_models_visual(models, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2847bd-fe77-4552-b3b0-1293c919682a",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" style=\"width: 100%; overflow: hidden; white-space: nowrap; text-align: center; margin: 60px 0; user-select: none;\">\n",
    "    <span style=\"color: #d97706; font-size: 18px; letter-spacing: 15px; opacity: 0.6;\">\n",
    "        ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆\n",
    "    </span>\n",
    "    <div style=\"font-size: 12px; color: #9ca3af; margin-top: -10px; background: #fff; display: inline-block; padding: 0 15px; position: relative; bottom: 12px;\">\n",
    "        Next Challenge\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a13eb95-65c9-4eeb-8ae6-dea1ab6ec3cf",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "### چالش 4: (Hyperparameter Tuning)\n",
    "\n",
    "مدل Random Forest پتانسیل بالایی دارد، اما تنظیمات پیش‌فرض آن (default parameters) بهینه نیستند. ما می‌خواهیم با تنظیم دقیق پیچ‌ومهره‌های مدل، خطا را کاهش دهیم.\n",
    "\n",
    "#### ماموریت ۱\n",
    "یک `GridSearchCV` طراحی کنید که پارامترهای زیر را بررسی کند:\n",
    "\n",
    "* **n_estimators:** تعداد درخت‌ها (مثلاً ۵۰، ۱۰۰، ۲۰۰)\n",
    "* **max_depth:** عمق هر درخت (برای جلوگیری از حفظ کردن داده‌ها - مثلاً ۱۰، ۲۰، `None`)\n",
    "* **min_samples_split:** حداقل نمونه برای انشعاب.\n",
    "\n",
    "**گزارش:**\n",
    "بهترین پارامترها چه بودند؟ آیا محدود کردن `max_depth` باعث کاهش Overfitting شد؟\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### ماموریت ۲\n",
    "۱. از داخل مدلِ بهینه شده‌ی خود (Best Estimator)، اولین درخت را استخراج کنید (در sklearn با دستور `model.estimators_[0]` قابل دسترسی است).\n",
    "۲. با استفاده از تابع `plot_tree`، نمودار این درخت را رسم کنید.\n",
    "۳. مقایسه تصویری:\n",
    "* یک بار نمودار را برای مدلی با `max_depth=None` (آزاد) بکشید.\n",
    "* یک بار نمودار را برای مدلی با `max_depth=3` (محدود) بکشید.\n",
    "\n",
    "\n",
    "\n",
    "**سوال تحلیلی:**\n",
    "به شاخ و برگ‌های درخت اول (عمق نامحدود) نگاه کنید. آیا گره‌هایی را می‌بینید که فقط ۱ نمونه در آن‌ها وجود دارد؟\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b1245d-b0d4-4876-8d59-c9c2b2dbcb92",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "#### راهنمایی برای ماموریت ۲\n",
    "\n",
    "برای رسم نمودار این بخش، می‌توانید از ساختار قطعه کد زیر الگوبرداری کنید:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce2803c-290a-480b-9ced-3b197eaaf59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "def visualize_tree(rf_model, feature_names, max_depth=None):\n",
    "    # انتخاب اولین درخت از جنگل\n",
    "    single_tree = rf_model.estimators_[0]\n",
    "    \n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plot_tree(single_tree, \n",
    "              feature_names=feature_names, \n",
    "              filled=True, \n",
    "              rounded=True, \n",
    "              max_depth=max_depth, # فقط تا عمق مشخصی را نشان بده تا خوانا باشد\n",
    "              fontsize=10)\n",
    "    plt.title(f\"Decision Tree Visualization (Max Depth: {max_depth})\")\n",
    "    plt.show()\n",
    "\n",
    "# نحوه استفاده:\n",
    "# visualize_tree(best_rf_model, X_train.columns, max_depth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71990459-afe1-479b-97ec-79a32d3d7308",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" style=\"width: 100%; overflow: hidden; white-space: nowrap; text-align: center; margin: 60px 0; user-select: none;\">\n",
    "    <span style=\"color: #d97706; font-size: 18px; letter-spacing: 15px; opacity: 0.6;\">\n",
    "        ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆\n",
    "    </span>\n",
    "    <div style=\"font-size: 12px; color: #9ca3af; margin-top: -10px; background: #fff; display: inline-block; padding: 0 15px; position: relative; bottom: 12px;\">\n",
    "        Next Challenge\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705a4b79-d624-4a96-b3c2-b57c00e40d1b",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "### چالش 5: پیش‌بینی بازه اطمینان (Quantile Regression)\n",
    "\n",
    "تا الان همه مدل‌ها تلاش می‌کردند بگویند: \"نمره علی ۱۴ می‌شود\". اما در دنیای واقعی، ما باید ریسک را هم بسنجیم. مدیر مدرسه می‌خواهد بداند: \"بدترین حالت و بهترین حالت نمره علی چند است؟\"\n",
    "مدل‌های معمولی (MSE Loss) میانگین را پیش‌بینی می‌کنند. ما می‌خواهیم چارک‌ها (Quantiles) را پیش‌بینی کنیم.\n",
    "\n",
    "####  ماموریت:\n",
    "به جای یک مدل، ۳ مدل `GradientBoostingRegressor` آموزش دهید:\n",
    "\n",
    "1. با `loss='quantile'` و `alpha=0.05` (پیش‌بینی بدبینانه - کف نمره).\n",
    "2. با `loss='quantile'` و `alpha=0.50` (همان میانه - پیش‌بینی نرمال).\n",
    "3. با `loss='quantile'` و `alpha=0.95` (پیش‌بینی خوش‌بینانه - سقف نمره).\n",
    "\n",
    "#### خروجی:\n",
    "برای ۵ دانش‌آموز از داده تست، نموداری بکشید که یک خط عمودی (بازه اطمینان) داشته باشد.\n",
    "\n",
    "\n",
    "\n",
    "**مثال:** مدل می‌گوید نمره سارا با اطمینان ۹۰٪ بین ۱۲ تا ۱۷ خواهد بود.\n",
    "\n",
    "**سوال تحلیلی:** دانش‌آموزی که بازه اطمینانش کوچک است (مثلاً ۱۵ تا ۱۶) با دانش‌آموزی که بازه بزرگی دارد (۱۰ تا ۱۸) چه تفاوتی در ویژگی‌ها دارند؟ (کشف عدم قطعیت).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11603f2-db5b-4d23-a527-a8b4dc8087fe",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" style=\"width: 100%; overflow: hidden; white-space: nowrap; text-align: center; margin: 60px 0; user-select: none;\">\n",
    "    <span style=\"color: #d97706; font-size: 18px; letter-spacing: 15px; opacity: 0.6;\">\n",
    "        ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆\n",
    "    </span>\n",
    "    <div style=\"font-size: 12px; color: #9ca3af; margin-top: -10px; background: #fff; display: inline-block; padding: 0 15px; position: relative; bottom: 12px;\">\n",
    "        Next Challenge\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c73851-21bd-484d-8398-2adfc8c3736a",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "### چالش 6: تحلیل متقابل (Counterfactual Analysis)\n",
    "\n",
    "مدیر مدرسه نمی‌خواهد فقط نمره را بداند، او می‌خواهد بداند \"چطور نمره را تغییر دهد؟\". در علم داده سنتی، ما فقط همبستگی (Feature Importance) را می‌بینیم. اما در اینجا می‌خواهیم تأثیر تغییر یک ویژگی را شبیه‌سازی کنیم. این مفهوم به نام **Causal Inference** یا استنتاج علیتی نزدیک است.\n",
    "\n",
    "####  ماموریت:\n",
    "یک دانش‌آموز ضعیف (نمره زیر ۱۰) را از داده‌های تست انتخاب کنید.\n",
    "\n",
    "1.  بدون تغییر دادن بقیه ویژگی‌ها، فقط مقدار `studytime` او را یکی‌یکی زیاد کنید (۱، ۲، ۳، ۴).\n",
    "2.  بدون تغییر دادن بقیه، فقط مقدار `absences` او را صفر کنید.\n",
    "3.  نمره جدید را با مدل پیش‌بینی کنید.\n",
    "\n",
    "\n",
    "\n",
    "#### نمودار \"What-If\":\n",
    "نموداری بکشید که محور افقی آن \"تغییرات\" باشد و محور عمودی \"نمره پیش‌بینی شده\".\n",
    "\n",
    "**سوال :** برای این دانش‌آموز خاص، کدام استراتژی موثرتر است؟ \"افزایش ۱ ساعت مطالعه\" یا \"کاهش ۱۰ جلسه غیبت\"؟\n",
    "(این چالش نشان می‌دهد که نسخه پیچیده شده برای هر دانش‌آموز متفاوت است؛ برای یکی مطالعه مهم است، برای دیگری حضور در کلاس).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fa64cf-a5ca-4841-b60c-1d71045bda89",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" style=\"width: 100%; overflow: hidden; white-space: nowrap; text-align: center; margin: 60px 0; user-select: none;\">\n",
    "    <span style=\"color: #d97706; font-size: 18px; letter-spacing: 15px; opacity: 0.6;\">\n",
    "        ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆ ◆\n",
    "    </span>\n",
    "    <div style=\"font-size: 12px; color: #9ca3af; margin-top: -10px; background: #fff; display: inline-block; padding: 0 15px; position: relative; bottom: 12px;\">\n",
    "        Next Challenge\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052fff67-8f8e-4c95-a956-cfe130dec4ee",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "### تمرین نهایی (پیش‌بینی روی داده‌های واقعی)\n",
    "\n",
    "تا الان هر مدلی تست می‌کردید داشتید روی مجموعه `validation` تست می‌کردید. حالا می‌خواهیم شما کد نهایی خود را آماده کنید شامل پایپ‌لاین‌های پاک‌سازی، مهندسی ویژگی و مدل‌سازی و در نهایت یک فایل پیش‌بینی برای داده‌های تست که ستون `G3` آن خالی است انجام دهید.\n",
    "\n",
    "بنابراین شما در نهایت باید یک فایل `CSV` به سرگروه‌های خود تحویل دهید که شامل پیش‌بینی ستون هدف باشد. نتایج شما با داده‌های نتایج واقعی تطبیق داده می‌شود و با معیار $RMSE$ نتیجه مدل نهایی شما مشخص می‌شود.\n",
    "\n",
    "---\n",
    "\n",
    "### راهنمای ارسال فایل نهایی (Submission Guide)\n",
    "\n",
    "برای اینکه مدل شما در سیستم داوری خودکار نمره بگیرد، فایل ارسالی باید دقیقاً طبق استاندارد زیر باشد. هرگونه مغایرت باعث می‌شود سیستم نمره شما را محاسبه نکند.\n",
    "\n",
    "#### ۱. فرمت فایل\n",
    "* فایل باید فرمت `csv` باشد.\n",
    "* نام فایل ترجیحاً `submission.csv` باشد.\n",
    "\n",
    "#### ۲. ساختار محتوا\n",
    "* فایل باید فقط یک ستون داشته باشد.\n",
    "* نام هدر (**Header**) این ستون باید دقیقاً **G3** باشد.\n",
    "* تعداد ردیف‌ها باید دقیقاً برابر با تعداد ردیف‌های فایل `test.csv` باشد.\n",
    "* **بسیار مهم:** ترتیب ردیف‌ها نباید تغییر کند. پیش‌بینی ردیف اول فایل شما، باید مربوط به دانش‌آموز ردیف اول فایل `test.csv` باشد.\n",
    "\n",
    "#### ۳. کد ذخیره‌سازی استاندارد\n",
    "برای اطمینان از صحت فایل، لطفاً در انتهای نوت‌بوک خود، از قطعه کد زیر برای ساخت فایل خروجی استفاده کنید:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cfeba5-a613-4c5d-b1b6-408c9515e254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# فرض کنید y_pred آرایه پیش‌بینی‌های نهایی شماست (روی داده‌های تست)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# ساخت دیتافریم\n",
    "submission = pd.DataFrame(y_pred, columns=['G3'])\n",
    "\n",
    "# ذخیره بدون ایندکس (بسیار مهم: index=False)\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"✅ فایل submission.csv با موفقیت ساخته شد.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f44af7a-2db4-43d4-b263-2cb1e32f44f0",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "### ❌ اشتباهات رایج (که باعث رد شدن مدل می‌شود):\n",
    "\n",
    "* **ذخیره با ایندکس:** اگر `index=False` را نگذارید، فایل شما دو ستون خواهد داشت (شماره ردیف و نمره). سیستم داوری ممکن است شماره ردیف را به اشتباه به عنوان نمره بخواند و خطای شما بسیار زیاد شود!\n",
    "* **بهم ریختن ترتیب:** اگر داده‌های تست را `Shuffle` کرده باشید، پیش‌بینی‌ها جابجا می‌شوند.\n",
    "* **تغییر نام ستون:** نام ستون نباید `Grade` یا `Pred` باشد، فقط **G3**.\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
